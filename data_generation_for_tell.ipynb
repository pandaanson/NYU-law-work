{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_and_output_dir='/Users/ansonkong/Downloads/Data for nyu work/'\n",
    "full_future_data_path='/Users/ansonkong/Downloads/rcp85hotter/'\n",
    "full_historical_data_path='/Users/ansonkong/Downloads/historic/'\n",
    "\n",
    "\n",
    "mapping_path = data_and_output_dir + 'output/merged_rb_control_area_mapping.csv'\n",
    "future_population_data_path = data_and_output_dir + 'input/Electric_Retail_Service_Territories/ssp3_county_population.csv'\n",
    "historical_population_data_path=data_and_output_dir + 'input/county_populations_2000_to_2020.csv'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "# Load control area mapping\n",
    "control_area_path = '/Users/ansonkong/Downloads/county_control_area_mapping_no_state_fips.csv'\n",
    "control_area_df = pd.read_csv(control_area_path)\n",
    "\n",
    "# Load meteorology data\n",
    "meteorology_path = '/Users/ansonkong/Downloads/rcp85hotter/2060/2060_01_01_02_UTC_County_Mean_Meteorology.csv'\n",
    "meteorology_df = pd.read_csv(meteorology_path)\n",
    "# Calculate wind speed\n",
    "meteorology_df['WSPD'] = np.sqrt(meteorology_df['U10']**2 + meteorology_df['V10']**2)\n",
    "# Add 'year' and 'UTC time' to meteorology data\n",
    "file_name = os.path.basename(meteorology_path)  # Gets '2060_01_01_01_UTC_County_Mean_Meteorology.csv'\n",
    "year_utc_time = file_name.split('_UTC')[0]  # Gets '2060_01_01_01'\n",
    "year = year_utc_time.split('_')[0]  # Gets '2060'\n",
    "utc_time = '_'.join(year_utc_time.split('_')[:4])  # Gets '2060_01_01_01'\n",
    "# Parse the original string to a datetime object\n",
    "dt = datetime.strptime(utc_time, '%Y_%m_%d_%H')\n",
    "\n",
    "# Format the datetime object to the desired format\n",
    "utc_time= dt.strftime('%-m/%-d/%Y %-I:%M:%S %p')\n",
    "meteorology_df['year'] = year\n",
    "meteorology_df['Time_UTC'] = utc_time\n",
    "# Merge on FIPS\n",
    "merged_df = pd.merge(control_area_df, meteorology_df, on='FIPS', how='inner')\n",
    "# Assuming population_data is loaded and prepared similarly\n",
    "# Perform interpolation (example shown for clarity; adjust as needed)\n",
    "years = np.arange(2020, 2101, 10)\n",
    "interp_years = np.arange(2020, 2101)\n",
    "\n",
    "for index, row in merged_df.iterrows():\n",
    "    pop_values = row[years.astype(str)].values\n",
    "    interpolator = interp1d(years, pop_values, kind='linear', fill_value=\"extrapolate\")\n",
    "    interpolated_values = interpolator(interp_years)\n",
    "    population_data.loc[index, interp_years.astype(str)] = interpolated_values\n",
    "# Example of grouping and applying weighted average\n",
    "def weighted_average(group, columns):\n",
    "    year_col = str(group['year'].iloc[0])  # Assuming year is constant within each group\n",
    "    weights = group[year_col]  # This assumes a direct match, which might need adjustment\n",
    "    return {col: np.average(group[col], weights=weights) for col in columns}\n",
    "\n",
    "# Assuming 'columns' is a list of meteorology columns to aggregate\n",
    "columns = meteorology_df.columns.difference(['FIPS', 'year', 'Time_UTC'])\n",
    "\n",
    "# Apply the weighted average within each group\n",
    "grouped = merged_df.groupby([ 'Majority_CNTRL_AREA', 'year', 'Time_UTC']).apply(lambda x: weighted_average(x, columns)).reset_index()\n",
    "\n",
    "\n",
    "expanded_grouped = grouped[0].apply(pd.Series)\n",
    "\n",
    "grouped_expanded = grouped.drop(columns=[0]).join(expanded_grouped)\n",
    "\n",
    "# 'grouped_expanded' now contains the original grouping columns and the expanded meteorology columns\n",
    "grouped_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/ansonkong/Downloads/Data for nyu work/rcp85hotter/2060/2060_01_01_02_UTC_County_Mean_Meteorology.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 69>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessed and saved: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Example usage for a single file\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m \u001b[43mprocess_meteorology_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_and_output_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrcp85hotter/2060/2060_01_01_02_UTC_County_Mean_Meteorology.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpopulation_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_population_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapping_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmapping_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_future\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     74\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Loop through all files in the future and historical directories\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m glob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_and_output_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrcp85hotter/*/*.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mprocess_meteorology_file\u001b[0;34m(file_path, population_df, mapping_df, is_future)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_meteorology_file\u001b[39m(file_path, population_df, mapping_df, is_future\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Load meteorology data\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     meteorology_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Calculate wind speed\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     meteorology_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWSPD\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(meteorology_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mU10\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m meteorology_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mV10\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1011\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1012\u001b[0m     dialect,\n\u001b[1;32m   1013\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[1;32m   1022\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:618\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    615\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    617\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 618\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1618\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1618\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1878\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1877\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1878\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1889\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/ansonkong/Downloads/Data for nyu work/rcp85hotter/2060/2060_01_01_02_UTC_County_Mean_Meteorology.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "import os\n",
    "from glob import glob\n",
    "debug=False\n",
    "# Define paths\n",
    "data_and_output_dir = '/Users/ansonkong/Downloads/Data for nyu work/'\n",
    "mapping_path = os.path.join(data_and_output_dir, 'output/merged_rb_control_area_mapping.csv')\n",
    "future_population_data_path = os.path.join(data_and_output_dir, 'input/Electric_Retail_Service_Territories/ssp3_county_population.csv')\n",
    "historical_population_data_path = os.path.join(data_and_output_dir, 'input/county_populations_2000_to_2020.csv')\n",
    "\n",
    "# Load mapping and population data\n",
    "mapping_df = pd.read_csv(mapping_path)\n",
    "future_population_df = pd.read_csv(future_population_data_path)\n",
    "historical_population_df = pd.read_csv(historical_population_data_path)\n",
    "\n",
    "\n",
    "# Function to process a single meteorology file\n",
    "def process_meteorology_file(file_path, population_df, mapping_df, is_future=True):\n",
    "    # Load meteorology data\n",
    "    meteorology_df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Calculate wind speed\n",
    "    meteorology_df['WSPD'] = np.sqrt(meteorology_df['U10']**2 + meteorology_df['V10']**2)\n",
    "    \n",
    "    # Extract date and time from file name\n",
    "    file_name = os.path.basename(file_path)\n",
    "    year, month, day, hour = map(int, file_name.split('_')[:4])\n",
    "    \n",
    "    # Format UTC time\n",
    "    utc_time = datetime(year, month, day, hour).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    meteorology_df['Time_UTC'] = utc_time\n",
    "    \n",
    "    # Merge with mapping\n",
    "    merged_df = pd.merge(mapping_df, meteorology_df, left_on='GEOID', right_on='FIPS', how='inner')\n",
    "\n",
    "    # Apply population weighting if future data\n",
    "    if is_future:\n",
    "        # Assuming future_population_df has columns for years and population projections\n",
    "        # Interpolate population data for the specific year\n",
    "        population_df['Year'] = population_df['Year'].astype(int)\n",
    "        pop_interpolator = interp1d(population_df['Year'], population_df[str(year)], kind='linear', fill_value=\"extrapolate\")\n",
    "        merged_df['Population'] = pop_interpolator(year)\n",
    "    else:\n",
    "        # For historical data, directly use the population for the year\n",
    "        merged_df = pd.merge(merged_df, population_df[['FIPS', f'pop_{year}']], on='FIPS', how='left')\n",
    "        merged_df.rename(columns={f'pop_{year}': 'Population'}, inplace=True)\n",
    "\n",
    "    # Ensure population column exists and handle any NaNs\n",
    "    merged_df['Population'].fillna(0, inplace=True)\n",
    "\n",
    "    # Group by RB and compute weighted averages for meteorological variables\n",
    "    def weighted_avg(group, var):\n",
    "        return np.average(group[var], weights=group['Population'])\n",
    "\n",
    "    variables = ['T2', 'Q2', 'SWDOWN', 'GLW', 'WSPD']\n",
    "    grouped = merged_df.groupby('rb').apply(lambda x: pd.Series({var: weighted_avg(x, var) for var in variables}))\n",
    "    grouped['Time_UTC'] = utc_time\n",
    "    grouped.reset_index(inplace=True)\n",
    "    \n",
    "    # Output file path\n",
    "    output_file = f\"{data_and_output_dir}output/{'future' if is_future else 'historical'}/{grouped['rb'][0]}_WRF_Hourly_Mean_Meteorology_{year}.csv\"\n",
    "    grouped.to_csv(output_file, index=False)\n",
    "    print(f\"Processed and saved: {output_file}\")\n",
    "# Example usage for a single file\n",
    "process_meteorology_file(\n",
    "    file_path=os.path.join(data_and_output_dir, 'rcp85hotter/2060/2060_01_01_02_UTC_County_Mean_Meteorology.csv'),\n",
    "    population_df=future_population_df,\n",
    "    mapping_df=mapping_df,\n",
    "    is_future=True\n",
    ")\n",
    "\n",
    "# Loop through all files in the future and historical directories\n",
    "for file_path in glob(os.path.join(data_and_output_dir, 'rcp85hotter/*/*.csv')):\n",
    "    process_meteorology_file(file_path, future_population_df, mapping_df, is_future=True)\n",
    "\n",
    "for file_path in glob(os.path.join(data_and_output_dir, 'historic/*/*.csv')):\n",
    "    process_meteorology_file(file_path, historical_population_df, mapping_df, is_future=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_meteorology_file(file_path, population_df, mapping_df, is_future):\n",
    "    # Load meteorology data\n",
    "    meteorology_df = pd.read_csv(file_path)\n",
    "    meteorology_df['WSPD'] = np.sqrt(meteorology_df['U10']**2 + meteorology_df['V10']**2)\n",
    "    \n",
    "    # Extract year, month, day, hour from file name\n",
    "    print(os.path.basename(file_path).split('_'))\n",
    "    year, month, day, hour, _, _, _, _ = os.path.basename(file_path).split('_')\n",
    "    \n",
    "    utc_time = datetime(int(year), int(month), int(day), int(hour[:-3])).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    meteorology_df['Time_UTC'] = utc_time\n",
    "    \n",
    "    # Merge meteorology data with mapping\n",
    "    merged_df = pd.merge(meteorology_df, mapping_df, left_on='FIPS', right_on='GEOID', how='inner')\n",
    "    \n",
    "    # Apply population weighting\n",
    "    if is_future:\n",
    "        # Interpolate future population data\n",
    "        year_col = f'pop_{year}'\n",
    "        merged_df = merged_df.merge(future_population_df[['GEOID', year_col]], on='GEOID')\n",
    "        merged_df['Population'] = merged_df[year_col]\n",
    "    else:\n",
    "        # Use historical population data\n",
    "        merged_df = merged_df.merge(historical_population_df[['GEOID', f'pop_{year}']], on='GEOID')\n",
    "        merged_df['Population'] = merged_df[f'pop_{year}']\n",
    "    \n",
    "    # Compute weighted averages\n",
    "    weighted_avg_cols = ['T2', 'Q2', 'SWDOWN', 'GLW', 'WSPD']\n",
    "    for col in weighted_avg_cols:\n",
    "        merged_df[col] = merged_df[col] * merged_df['Population']\n",
    "    grouped = merged_df.groupby('rb')[weighted_avg_cols + ['Population']].sum()\n",
    "    for col in weighted_avg_cols:\n",
    "        grouped[col] = grouped[col] / grouped['Population']\n",
    "    \n",
    "    # Save processed data by RB and year\n",
    "    for rb, group in grouped.iterrows():\n",
    "        output_file = f\"{data_and_output_dir}output/{'future' if is_future else 'historical'}/{rb}_WRF_Hourly_Mean_Meteorology_{year}.csv\"\n",
    "        group.drop('Population').to_csv(output_file, header=True)\n",
    "        print(f\"Processed and saved: {output_file}\")\n",
    "def process_all_files():\n",
    "    for file_path in glob(f\"{full_future_data_path}/**/*.csv\", recursive=True):\n",
    "        process_meteorology_file(file_path, future_population_df, mapping_df, is_future=True)\n",
    "    for file_path in glob(f\"{full_historical_data_path}/**/*.csv\", recursive=True):\n",
    "        process_meteorology_file(file_path, historical_population_df, mapping_df, is_future=False)\n",
    "\n",
    "process_all_files()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "STATEFP\n",
      "COUNTYFP\n",
      "COUNTYNS\n",
      "AFFGEOID\n",
      "GEOID\n",
      "NAME\n",
      "LSAD\n",
      "ALAND\n",
      "AWATER\n",
      "geometry\n",
      "FIPS_x\n",
      "rb\n",
      "is_mainland\n",
      "CNTRL_AREA\n",
      "FIPS_y\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "FIPS\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import os\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "debug=False\n",
    "# Define paths\n",
    "data_and_output_dir = '/Users/ansonkong/Downloads/Data for nyu work/'\n",
    "full_future_data_path = '/Users/ansonkong/Downloads/rcp85hotter/'\n",
    "full_historical_data_path = '/Users/ansonkong/Downloads/historic/'\n",
    "\n",
    "#this just smooth out operation\n",
    "cutoff_year=2020 #The year prediction dataset start\n",
    "start_year=2000 #The year historical \n",
    "end_year=2100\n",
    "\n",
    "\n",
    "\n",
    "#Path no need to update\n",
    "mapping_path = data_and_output_dir + 'output/merged_rb_control_area_mapping.csv'\n",
    "future_population_data_path = data_and_output_dir + 'input/Electric_Retail_Service_Territories/ssp3_county_population.csv'\n",
    "historical_population_data_path = data_and_output_dir + 'input/county_populations_2000_to_2020.csv'\n",
    "output_path = data_and_output_dir + 'output/'\n",
    "\n",
    "# Load mapping and population data\n",
    "mapping_df = pd.read_csv(mapping_path)\n",
    "future_population_df = pd.read_csv(future_population_data_path)\n",
    "historical_population_df = pd.read_csv(historical_population_data_path)\n",
    "\n",
    "years = np.arange(cutoff_year, end_year + 1, 10)\n",
    "interp_years = np.arange(cutoff_year, end_year + 1)\n",
    "\n",
    "# Ensure FIPS codes are zero-padded strings\n",
    "historical_population_df['county_FIPS'] = historical_population_df['county_FIPS'].astype(str).str.zfill(5)\n",
    "future_population_df['FIPS'] = future_population_df['FIPS'].astype(str).str.zfill(5)\n",
    "mapping_df['GEOID'] = mapping_df['GEOID'].astype(str).str.zfill(5)\n",
    "\n",
    "# Rename 'pop_{year}' columns to just '{year}'\n",
    "for year in range(start_year, cutoff_year+1):\n",
    "    if f'pop_{year}' in historical_population_df.columns:\n",
    "        historical_population_df.rename(columns={f'pop_{year}': str(year)}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Assuming 'FIPS' is the column to join on and 'Year' is the column indicating the year in future_population_df\n",
    "for index, row in future_population_df.iterrows():\n",
    "    pop_values = [row[str(year)] for year in years if str(year) in row]\n",
    "    interpolator = interp1d(years, pop_values, kind='linear', fill_value=\"extrapolate\")\n",
    "    interpolated_values = interpolator(interp_years)\n",
    "    for year in interp_years:\n",
    "        future_population_df.at[index, str(year)] = interpolated_values[year - cutoff_year]\n",
    "\n",
    "\n",
    "# Select relevant columns for historical data\n",
    "historical_population_df['FIPS']=historical_population_df['county_FIPS']\n",
    "historical_population_df = historical_population_df[['FIPS'] + [str(year) for year in range(start_year, cutoff_year)]]\n",
    "\n",
    "# Select relevant columns for future data\n",
    "future_population_df = future_population_df[['FIPS'] + [str(year) for year in interp_years]]\n",
    "\n",
    "# Concatenate historical and future dataframes\n",
    "combined_population_df = pd.concat([historical_population_df, future_population_df]).drop_duplicates(subset=['FIPS']).reset_index(drop=True)\n",
    "# Merge combined population data with mapping data\n",
    "# Assuming 'GEOID' in mapping_df corresponds to 'FIPS' in population data\n",
    "combined_df = pd.merge(mapping_df, combined_population_df, left_on='GEOID', right_on='FIPS', how='inner')\n",
    "combined_df['FIPS']=combined_df['GEOID']\n",
    "# Identify FIPS codes in mapping_df that did not successfully join\n",
    "missing_in_combined = set(mapping_df['GEOID']) - set(combined_df['GEOID'])\n",
    "print(missing_in_combined)\n",
    "for column in combined_df.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process start for year: 2000\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p1_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p1\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p10_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p10\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p100_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p100\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p101_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p101\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p102_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p102\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p103_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p103\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p104_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p104\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p105_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p105\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p106_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p106\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p107_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p107\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p108_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p108\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p109_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p109\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p11_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p11\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p110_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p110\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p111_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p111\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p112_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p112\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p113_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p113\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p114_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p114\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p115_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p115\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p116_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p116\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p117_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p117\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p118_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p118\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p119_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p119\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p12_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p12\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p120_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p120\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p121_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p121\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p122_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p122\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p123_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p123\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p124_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p124\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p125_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p125\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p126_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p126\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p127_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p127\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p128_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p128\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p129_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p129\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p13_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p13\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p130_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p130\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p131_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p131\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p132_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p132\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p133_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p133\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p134_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p134\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p14_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p14\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p15_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p15\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p16_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p16\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p17_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p17\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p18_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p18\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p19_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p19\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p2_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p2\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p20_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p20\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p21_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p21\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p22_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p22\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p23_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p23\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p24_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p24\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p25_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p25\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p26_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p26\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p27_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p27\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p28_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p28\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p29_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p29\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p3_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p3\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p30_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p30\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p31_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p31\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p32_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p32\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p33_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p33\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p34_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p34\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p35_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p35\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p36_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p36\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p37_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p37\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p38_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p38\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p39_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p39\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p4_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p4\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p40_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p40\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p41_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p41\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p42_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p42\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p43_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p43\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p44_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p44\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p45_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p45\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p46_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p46\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p47_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p47\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p48_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p48\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p49_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p49\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p5_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p5\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p50_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p50\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p51_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p51\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p52_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p52\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p53_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p53\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p54_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p54\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p55_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p55\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p56_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p56\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p57_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p57\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p58_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p58\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p59_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p59\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p6_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p6\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p60_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p60\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p61_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p61\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p62_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p62\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p63_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p63\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p64_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p64\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p65_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p65\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p66_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p66\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p67_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p67\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p68_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p68\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p69_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p69\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p7_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p7\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p70_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p70\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p71_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p71\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p72_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p72\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p73_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p73\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p74_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p74\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p75_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p75\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p76_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p76\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p77_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p77\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p78_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p78\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p79_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p79\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p8_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p8\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p80_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p80\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p81_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p81\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p82_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p82\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p83_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p83\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p84_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p84\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p85_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p85\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p86_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p86\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p87_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p87\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p88_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p88\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p89_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p89\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p9_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p9\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p90_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p90\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p91_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p91\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p92_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p92\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p93_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p93\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p94_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p94\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p95_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p95\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p96_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p96\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p97_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p97\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p98_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p98\n",
      "Processed and saved: /Users/ansonkong/Downloads/Data for nyu work/output/historical_weather/p99_WRF_Hourly_Mean_Meteorology_2000.csv for RB: p99\n"
     ]
    }
   ],
   "source": [
    "# Ensure output directories exist\n",
    "debug=True\n",
    "historical_weather_path = os.path.join(output_path, 'historical_weather')\n",
    "future_weather_path = os.path.join(output_path, 'future_weather')\n",
    "os.makedirs(historical_weather_path, exist_ok=True)\n",
    "os.makedirs(future_weather_path, exist_ok=True)\n",
    "yearloopbreaker=False\n",
    "fileloopbreaker=False\n",
    "rbloopbreaker=False\n",
    "for year in range(start_year, end_year + 1):\n",
    "\n",
    "    if yearloopbreaker:break\n",
    "\n",
    "\n",
    "    print(f'Process start for year: {year}')\n",
    "    if year <= cutoff_year:\n",
    "        folder_to_read = os.path.join(full_historical_data_path, str(year))\n",
    "        folder_to_store = historical_weather_path\n",
    "    else:\n",
    "        folder_to_read = os.path.join(full_future_data_path, str(year))\n",
    "        folder_to_store = future_weather_path\n",
    "    \n",
    "    # Initialize a dictionary to hold DataFrames for each rb\n",
    "    rb_dfs = {}\n",
    "\n",
    "    # Iterate through each file in the year's folder\n",
    "    for file_path in glob(os.path.join(folder_to_read, '*.csv')):\n",
    "        \n",
    "        if fileloopbreaker:break\n",
    "        \n",
    "        meteorology_df = pd.read_csv(file_path)\n",
    "        #print(meteorology_df.columns)\n",
    "        meteorology_df['FIPS'] = meteorology_df['FIPS'].astype(str).str.zfill(5)\n",
    "        meteorology_df['WSPD'] = np.sqrt(meteorology_df['U10']**2 + meteorology_df['V10']**2)\n",
    "        \n",
    "        # Extract date and time from file name\n",
    "        _, month, day, hour = map(int, os.path.basename(file_path).split('_')[:4])\n",
    "        utc_time = datetime(year, month, day, hour).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        meteorology_df['Time_UTC'] = utc_time\n",
    "        \n",
    "        # Merge with background data\n",
    "        merged_df = pd.merge(combined_df, meteorology_df, on='FIPS', how='inner')\n",
    "        \n",
    "        # Calculate weighted averages and accumulate in rb_dfs\n",
    "        merged_df['Population'] = merged_df[str(year)]\n",
    "        for rb, group in merged_df.groupby('rb'):\n",
    "            if rbloopbreaker:break\n",
    "            \n",
    "            if rb not in rb_dfs:\n",
    "                rb_dfs[rb] = pd.DataFrame()\n",
    "            weighted = group.copy()\n",
    "            for col in ['T2', 'Q2', 'SWDOWN', 'GLW', 'WSPD']:\n",
    "                weighted[col] = weighted[col] * weighted['Population']\n",
    "            weighted_sum = weighted.groupby('rb').sum()\n",
    "            for col in ['T2', 'Q2', 'SWDOWN', 'GLW', 'WSPD']:\n",
    "                weighted_sum[col] = weighted_sum[col] / weighted_sum['Population']\n",
    "            weighted_sum['Time_UTC'] = utc_time\n",
    "            rb_dfs[rb] = pd.concat([rb_dfs[rb], weighted_sum.reset_index()], ignore_index=True)\n",
    "        if debug:\n",
    "            fileloopbreaker=True\n",
    "            yearloopbreaker=True\n",
    "\n",
    "    \n",
    "    # Save each RB's accumulated data to its file\n",
    "    for rb, df in rb_dfs.items():\n",
    "        output_file = os.path.join(folder_to_store, f\"{rb}_WRF_Hourly_Mean_Meteorology_{year}.csv\")\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Processed and saved: {output_file} for RB: {rb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8v/68yqll_54lzgb57b5q8_fbrc0000gn/T/ipykernel_15603/598961565.py:4: DtypeWarning: Columns (5,6,7,8,9,10,11,13,14,15,16,17,18,19,20,21,22,23,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  balance_df = pd.read_csv('/Users/ansonkong/Downloads/Data for nyu work/Input/EIA 930/BA/EIA930_BALANCE_2020_Jan_Jun.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct Sub-Region: 82\n",
      "Number of distinct Balancing Authority in SUBREGION: 8\n",
      "Number of distinct Balancing Authority in BALANCE not in SUBREGION: 45\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "balance_df = pd.read_csv('/Users/ansonkong/Downloads/Data for nyu work/Input/EIA 930/BA/EIA930_BALANCE_2020_Jan_Jun.csv')\n",
    "subregion_df = pd.read_csv('/Users/ansonkong/Downloads/Data for nyu work/Input/EIA 930/Subregion/EIA930_SUBREGION_2020_Jan_Jun.csv')\n",
    "\n",
    "# Filter the datasets\n",
    "balance_df_filtered = balance_df[(balance_df['UTC Time at End of Hour'] == '02/01/2020 7:00:00 AM')& (balance_df['Demand (MW)'].notna())]\n",
    "subregion_df_filtered = subregion_df[(subregion_df['UTC Time at End of Hour'] == '02/01/2020 7:00:00 AM') & (subregion_df['Demand (MW)'].notna())]\n",
    "\n",
    "# Get the number of distinct Sub-Region and Balancing Authority for SUBREGION\n",
    "distinct_sub_region = subregion_df_filtered['Sub-Region'].nunique()\n",
    "distinct_ba_subregion = subregion_df_filtered['Balancing Authority'].nunique()\n",
    "\n",
    "# For BALANCE, find distinct Balancing Authority not in SUBREGION\n",
    "distinct_ba_balance = balance_df_filtered[~balance_df_filtered['Balancing Authority'].isin(subregion_df_filtered['Balancing Authority'])]['Balancing Authority'].nunique()\n",
    "\n",
    "print(f\"Number of distinct Sub-Region: {distinct_sub_region}\")\n",
    "print(f\"Number of distinct Balancing Authority in SUBREGION: {distinct_ba_subregion}\")\n",
    "print(f\"Number of distinct Balancing Authority in BALANCE not in SUBREGION: {distinct_ba_balance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_and_output_dir = '/Users/ansonkong/Downloads/Data for nyu work/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8v/68yqll_54lzgb57b5q8_fbrc0000gn/T/ipykernel_15603/3776213816.py:13: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(directory, file), usecols=cols)\n",
      "/var/folders/8v/68yqll_54lzgb57b5q8_fbrc0000gn/T/ipykernel_15603/3776213816.py:13: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(directory, file), usecols=cols)\n",
      "/var/folders/8v/68yqll_54lzgb57b5q8_fbrc0000gn/T/ipykernel_15603/3776213816.py:13: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(directory, file), usecols=cols)\n",
      "/var/folders/8v/68yqll_54lzgb57b5q8_fbrc0000gn/T/ipykernel_15603/3776213816.py:13: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(directory, file), usecols=cols)\n",
      "/var/folders/8v/68yqll_54lzgb57b5q8_fbrc0000gn/T/ipykernel_15603/3776213816.py:13: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(directory, file), usecols=cols)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Paths to the directories\n",
    "subregion_dir = data_and_output_dir+'Input/EIA 930/Subregion/'\n",
    "ba_dir = data_and_output_dir+'Input/EIA 930/BA/'\n",
    "\n",
    "# Function to read and merge CSVs from a directory\n",
    "def read_and_merge_csvs(directory, cols):\n",
    "    combined_df = pd.DataFrame()\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith('.csv'):\n",
    "            df = pd.read_csv(os.path.join(directory, file), usecols=cols)\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "# Columns to keep for each dataset\n",
    "subregion_cols = ['UTC Time at End of Hour', 'Demand (MW)', 'Sub-Region', 'Balancing Authority']\n",
    "ba_cols = ['UTC Time at End of Hour', 'Balancing Authority', 'Demand (MW)']\n",
    "\n",
    "# Read and merge CSVs\n",
    "subregion_combined_df = read_and_merge_csvs(subregion_dir, subregion_cols)\n",
    "ba_combined_df = read_and_merge_csvs(ba_dir, ba_cols)\n",
    "\n",
    "# Before the loop, initialize an empty list to collect new rows\n",
    "new_rows = []\n",
    "\n",
    "# Iterate over BA combined dataframe to check for missing Balancing Authorities in Subregion dataframe\n",
    "for index, row in ba_combined_df.iterrows():\n",
    "    matching_rows = subregion_combined_df[(subregion_combined_df['UTC Time at End of Hour'] == row['UTC Time at End of Hour']) & \n",
    "                                           (subregion_combined_df['Balancing Authority'] == row['Balancing Authority'])]\n",
    "    if matching_rows.empty:\n",
    "        # If no matching row, prepare the new row with adjustments\n",
    "        new_row = row.to_dict()\n",
    "        new_row['Sub-Region'] = new_row['Balancing Authority']  # Set Sub-Region to Balancing Authority value\n",
    "        new_rows.append(new_row)\n",
    "\n",
    "# After the loop, add all new rows to the dataframe at once\n",
    "if new_rows:  # Check if there are any new rows to add\n",
    "    subregion_combined_df = pd.concat([subregion_combined_df, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "\n",
    "# You may now use subregion_combined_df with the added records.\n",
    "# Optionally, you can save this dataframe to a new CSV file\n",
    "subregion_combined_df.to_csv(data_and_output_dir+'output/merged_subregion_with_ba.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balancing Authority</th>\n",
       "      <th>Data Date</th>\n",
       "      <th>Hour Number</th>\n",
       "      <th>Sub-Region</th>\n",
       "      <th>Demand (MW)</th>\n",
       "      <th>Local Time at End of Hour</th>\n",
       "      <th>UTC Time at End of Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CISO</td>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>1</td>\n",
       "      <td>PGAE</td>\n",
       "      <td>10,285</td>\n",
       "      <td>01/01/2020 1:00:00 AM</td>\n",
       "      <td>01/01/2020 9:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CISO</td>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>1</td>\n",
       "      <td>SCE</td>\n",
       "      <td>9,390</td>\n",
       "      <td>01/01/2020 1:00:00 AM</td>\n",
       "      <td>01/01/2020 9:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CISO</td>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>1</td>\n",
       "      <td>SDGE</td>\n",
       "      <td>2,016</td>\n",
       "      <td>01/01/2020 1:00:00 AM</td>\n",
       "      <td>01/01/2020 9:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CISO</td>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>1</td>\n",
       "      <td>VEA</td>\n",
       "      <td>119</td>\n",
       "      <td>01/01/2020 1:00:00 AM</td>\n",
       "      <td>01/01/2020 9:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CISO</td>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>2</td>\n",
       "      <td>PGAE</td>\n",
       "      <td>9,934</td>\n",
       "      <td>01/01/2020 2:00:00 AM</td>\n",
       "      <td>01/01/2020 10:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362471</th>\n",
       "      <td>SWPP</td>\n",
       "      <td>06/30/2020</td>\n",
       "      <td>24</td>\n",
       "      <td>SPRM</td>\n",
       "      <td>427</td>\n",
       "      <td>07/01/2020 12:00:00 AM</td>\n",
       "      <td>07/01/2020 5:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362472</th>\n",
       "      <td>SWPP</td>\n",
       "      <td>06/30/2020</td>\n",
       "      <td>24</td>\n",
       "      <td>SPS</td>\n",
       "      <td>4,523</td>\n",
       "      <td>07/01/2020 12:00:00 AM</td>\n",
       "      <td>07/01/2020 5:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362473</th>\n",
       "      <td>SWPP</td>\n",
       "      <td>06/30/2020</td>\n",
       "      <td>24</td>\n",
       "      <td>WAUE</td>\n",
       "      <td>2,956</td>\n",
       "      <td>07/01/2020 12:00:00 AM</td>\n",
       "      <td>07/01/2020 5:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362474</th>\n",
       "      <td>SWPP</td>\n",
       "      <td>06/30/2020</td>\n",
       "      <td>24</td>\n",
       "      <td>WFEC</td>\n",
       "      <td>1,257</td>\n",
       "      <td>07/01/2020 12:00:00 AM</td>\n",
       "      <td>07/01/2020 5:00:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362475</th>\n",
       "      <td>SWPP</td>\n",
       "      <td>06/30/2020</td>\n",
       "      <td>24</td>\n",
       "      <td>WR</td>\n",
       "      <td>4,670</td>\n",
       "      <td>07/01/2020 12:00:00 AM</td>\n",
       "      <td>07/01/2020 5:00:00 AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362476 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Balancing Authority   Data Date  Hour Number Sub-Region Demand (MW)  \\\n",
       "0                     CISO  01/01/2020            1       PGAE      10,285   \n",
       "1                     CISO  01/01/2020            1        SCE       9,390   \n",
       "2                     CISO  01/01/2020            1       SDGE       2,016   \n",
       "3                     CISO  01/01/2020            1        VEA         119   \n",
       "4                     CISO  01/01/2020            2       PGAE       9,934   \n",
       "...                    ...         ...          ...        ...         ...   \n",
       "362471                SWPP  06/30/2020           24       SPRM         427   \n",
       "362472                SWPP  06/30/2020           24        SPS       4,523   \n",
       "362473                SWPP  06/30/2020           24       WAUE       2,956   \n",
       "362474                SWPP  06/30/2020           24       WFEC       1,257   \n",
       "362475                SWPP  06/30/2020           24         WR       4,670   \n",
       "\n",
       "       Local Time at End of Hour UTC Time at End of Hour  \n",
       "0          01/01/2020 1:00:00 AM   01/01/2020 9:00:00 AM  \n",
       "1          01/01/2020 1:00:00 AM   01/01/2020 9:00:00 AM  \n",
       "2          01/01/2020 1:00:00 AM   01/01/2020 9:00:00 AM  \n",
       "3          01/01/2020 1:00:00 AM   01/01/2020 9:00:00 AM  \n",
       "4          01/01/2020 2:00:00 AM  01/01/2020 10:00:00 AM  \n",
       "...                          ...                     ...  \n",
       "362471    07/01/2020 12:00:00 AM   07/01/2020 5:00:00 AM  \n",
       "362472    07/01/2020 12:00:00 AM   07/01/2020 5:00:00 AM  \n",
       "362473    07/01/2020 12:00:00 AM   07/01/2020 5:00:00 AM  \n",
       "362474    07/01/2020 12:00:00 AM   07/01/2020 5:00:00 AM  \n",
       "362475    07/01/2020 12:00:00 AM   07/01/2020 5:00:00 AM  \n",
       "\n",
       "[362476 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance_df_filtered[['Balancing Authority','Sub-Region']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the shapefile:\n",
      "Index(['STATEFP', 'COUNTYFP', 'COUNTYNS', 'AFFGEOID', 'GEOID', 'NAME', 'LSAD',\n",
      "       'ALAND', 'AWATER', 'geometry'],\n",
      "      dtype='object')\n",
      "\n",
      "Columns in the CSV file:\n",
      "Index(['Year', 'State_FIPS', 'State_Name', 'County_FIPS', 'County_Name',\n",
      "       'BA_Number', 'BA_Code'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming data_and_output_dir is defined and contains the path to your data directory\n",
    "data_and_output_dir = '/Users/ansonkong/Downloads/Data for nyu work/' # Update this path\n",
    "\n",
    "# Path to the shapefile and CSV\n",
    "shapefile_path = data_and_output_dir + 'Input/cb_2018_us_county_500k/cb_2018_us_county_500k.shp'\n",
    "csv_path = data_and_output_dir + 'Input/ba_service_territory_2020.csv'\n",
    "\n",
    "# Read the shapefile using GeoPandas\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Read the CSV file. Use GeoPandas if you expect to work with geographic data in the CSV.\n",
    "# If the CSV doesn't contain geographic data, you could just use pandas with pd.read_csv(csv_path)\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Print all columns from the shapefile\n",
    "print(\"Columns in the shapefile:\")\n",
    "print(gdf.columns)\n",
    "\n",
    "# Print all columns from the CSV file\n",
    "print(\"\\nColumns in the CSV file:\")\n",
    "print(df.columns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

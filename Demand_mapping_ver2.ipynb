{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This part of code, the goal is to go from mapping and county level weather data to to subgroup data\n",
    "# Define paths\n",
    "data_and_output_dir = '/Users/ansonkong/Downloads/Data for nyu work/'\n",
    "full_future_data_path = '/Users/ansonkong/Downloads/rcp85hotter/'\n",
    "full_historical_data_path = '/Users/ansonkong/Downloads/historic/'\n",
    "\n",
    "#this just smooth out operation\n",
    "cutoff_year=2020 #The year prediction dataset start\n",
    "start_year=2000 #The year historical \n",
    "end_year=2100\n",
    "\n",
    "#Debug mode(only output once)\n",
    "debug=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this version is no need for mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n",
      "/var/folders/8v/68yqll_54lzgb57b5q8_fbrc0000gn/T/ipykernel_1506/1708899298.py:17: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(directory, file), usecols=cols)\n",
      "/var/folders/8v/68yqll_54lzgb57b5q8_fbrc0000gn/T/ipykernel_1506/1708899298.py:17: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(directory, file), usecols=cols)\n",
      "/var/folders/8v/68yqll_54lzgb57b5q8_fbrc0000gn/T/ipykernel_1506/1708899298.py:17: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(directory, file), usecols=cols)\n",
      "/var/folders/8v/68yqll_54lzgb57b5q8_fbrc0000gn/T/ipykernel_1506/1708899298.py:17: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(directory, file), usecols=cols)\n",
      "/var/folders/8v/68yqll_54lzgb57b5q8_fbrc0000gn/T/ipykernel_1506/1708899298.py:17: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(directory, file), usecols=cols)\n"
     ]
    }
   ],
   "source": [
    "#import require file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import os\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "\n",
    "ba_dir = data_and_output_dir+'Input/EIA 930/BA/'\n",
    "\n",
    "\n",
    "# Function to read and merge CSVs from a directory\n",
    "def read_and_merge_csvs(directory, cols):\n",
    "    combined_df = pd.DataFrame()\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith('.csv'):\n",
    "            df = pd.read_csv(os.path.join(directory, file), usecols=cols)\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "ba_cols = ['UTC Time at End of Hour', 'Balancing Authority', 'Demand (MW)']\n",
    "ba_combined_df = read_and_merge_csvs(ba_dir, ba_cols)\n",
    "\n",
    "\n",
    "\n",
    "#Path, this will update itself\n",
    "mapping_path = data_and_output_dir + 'output/merged_rb_control_area_mapping.csv'\n",
    "future_population_data_path = data_and_output_dir + 'input/Electric_Retail_Service_Territories/ssp3_county_population.csv'\n",
    "historical_population_data_path = data_and_output_dir + 'input/county_populations_2000_to_2020.csv'\n",
    "output_path = data_and_output_dir + 'output/'\n",
    "\n",
    "# Load mapping and population data\n",
    "mapping_df = pd.read_csv(mapping_path)\n",
    "future_population_df = pd.read_csv(future_population_data_path)\n",
    "historical_population_df = pd.read_csv(historical_population_data_path)\n",
    "\n",
    "#crate looping for interp\n",
    "years = np.arange(cutoff_year, end_year + 1, 10)\n",
    "interp_years = np.arange(cutoff_year, end_year + 1)\n",
    "\n",
    "# Ensure FIPS codes are five zero-padded strings\n",
    "historical_population_df['FIPS'] = historical_population_df['county_FIPS'].astype(str).str.zfill(5)\n",
    "future_population_df['FIPS'] = future_population_df['FIPS'].astype(str).str.zfill(5)\n",
    "mapping_df['GEOID'] = mapping_df['GEOID'].astype(str).str.zfill(5)\n",
    "\n",
    "# Rename 'pop_{year}' columns to just '{year}'\n",
    "for year in range(start_year, cutoff_year+1):\n",
    "    if f'pop_{year}' in historical_population_df.columns:\n",
    "        historical_population_df.rename(columns={f'pop_{year}': str(year)}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Assuming 'FIPS' is the column to join on and 'Year' is the column indicating the year in future_population_df\n",
    "for index, row in future_population_df.iterrows():\n",
    "    pop_values = [row[str(year)] for year in years if str(year) in row]\n",
    "    interpolator = interp1d(years, pop_values, kind='linear', fill_value=\"extrapolate\")\n",
    "    interpolated_values = interpolator(interp_years)\n",
    "    for year in interp_years:\n",
    "        future_population_df.at[index, str(year)] = interpolated_values[year - cutoff_year]\n",
    "\n",
    "\n",
    "# Select relevant columns for historical data\n",
    "historical_population_df = historical_population_df[['FIPS'] + [str(year) for year in range(start_year, cutoff_year)]]\n",
    "\n",
    "# Select relevant columns for future data\n",
    "future_population_df = future_population_df[['FIPS'] + [str(year) for year in interp_years]]\n",
    "\n",
    "# Concatenate historical and future dataframes\n",
    "combined_population_df = pd.merge(historical_population_df, future_population_df, on='FIPS', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "serives_area_path = data_and_output_dir + '/Input/service_area'\n",
    "# Read the CSV file\n",
    "serives_area_df = read_and_merge_csvs(serives_area_path, ['BA_Code','County_FIPS','Year'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8v/68yqll_54lzgb57b5q8_fbrc0000gn/T/ipykernel_1506/2799943440.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '74434.99509211467' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  serives_area_df.at[idx, 'Population'] = population_value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>County_FIPS</th>\n",
       "      <th>BA_Code</th>\n",
       "      <th>Population</th>\n",
       "      <th>Total_Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>23003</td>\n",
       "      <td>NBSO</td>\n",
       "      <td>74434.995092</td>\n",
       "      <td>3.757132e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>23009</td>\n",
       "      <td>NBSO</td>\n",
       "      <td>53103.777044</td>\n",
       "      <td>3.757132e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>23019</td>\n",
       "      <td>NBSO</td>\n",
       "      <td>158886.075450</td>\n",
       "      <td>3.757132e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>23021</td>\n",
       "      <td>NBSO</td>\n",
       "      <td>18456.013671</td>\n",
       "      <td>3.757132e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>23027</td>\n",
       "      <td>NBSO</td>\n",
       "      <td>38974.016788</td>\n",
       "      <td>3.757132e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26339</th>\n",
       "      <td>2015</td>\n",
       "      <td>48483</td>\n",
       "      <td>SWPP</td>\n",
       "      <td>5664.000000</td>\n",
       "      <td>1.879542e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26340</th>\n",
       "      <td>2015</td>\n",
       "      <td>48485</td>\n",
       "      <td>SWPP</td>\n",
       "      <td>131034.000000</td>\n",
       "      <td>1.879542e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26341</th>\n",
       "      <td>2015</td>\n",
       "      <td>48487</td>\n",
       "      <td>SWPP</td>\n",
       "      <td>13067.000000</td>\n",
       "      <td>1.879542e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26342</th>\n",
       "      <td>2015</td>\n",
       "      <td>48499</td>\n",
       "      <td>SWPP</td>\n",
       "      <td>43119.000000</td>\n",
       "      <td>1.879542e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26343</th>\n",
       "      <td>2015</td>\n",
       "      <td>48501</td>\n",
       "      <td>SWPP</td>\n",
       "      <td>8648.000000</td>\n",
       "      <td>1.879542e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26344 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year County_FIPS BA_Code     Population  Total_Population\n",
       "0      2020       23003    NBSO   74434.995092      3.757132e+05\n",
       "1      2020       23009    NBSO   53103.777044      3.757132e+05\n",
       "2      2020       23019    NBSO  158886.075450      3.757132e+05\n",
       "3      2020       23021    NBSO   18456.013671      3.757132e+05\n",
       "4      2020       23027    NBSO   38974.016788      3.757132e+05\n",
       "...     ...         ...     ...            ...               ...\n",
       "26339  2015       48483    SWPP    5664.000000      1.879542e+07\n",
       "26340  2015       48485    SWPP  131034.000000      1.879542e+07\n",
       "26341  2015       48487    SWPP   13067.000000      1.879542e+07\n",
       "26342  2015       48499    SWPP   43119.000000      1.879542e+07\n",
       "26343  2015       48501    SWPP    8648.000000      1.879542e+07\n",
       "\n",
       "[26344 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming serives_area_df and combined_population_df are already defined\n",
    "\n",
    "# Step 1: Add a placeholder for the population lookup\n",
    "serives_area_df['Population'] = 0\n",
    "serives_area_df['County_FIPS']=serives_area_df['County_FIPS'].astype(str).str.zfill(5)\n",
    "# Step 2: Populate 'Population' in serives_area_df by looking up in combined_population_df\n",
    "for idx, row in serives_area_df.iterrows():\n",
    "    county_fips = row['County_FIPS']\n",
    "    year = row['Year']\n",
    "    \n",
    "    # Find the matching row in combined_population_df by 'FIPS'\n",
    "    matching_population_row = combined_population_df[combined_population_df['FIPS'] == county_fips]\n",
    "    if not matching_population_row.empty and str(year) in combined_population_df.columns:\n",
    "        # If a matching row is found and the year column exists in combined_population_df,\n",
    "        # retrieve the population value\n",
    "        population_value = matching_population_row.iloc[0][str(year)]\n",
    "        serives_area_df.at[idx, 'Population'] = population_value\n",
    "\n",
    "# Step 3: Compute 'Total_Population' for each combination of 'Year' and 'BA_Code' in serives_area_df\n",
    "serives_area_df['Total_Population'] = serives_area_df.groupby(['Year', 'BA_Code'])['Population'].transform('sum')\n",
    "\n",
    "# The 'Total_Population' column now contains the summed population for each combination of Year and BA_Code\n",
    "serives_area_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Assuming ba_combined_df, serives_area_df, and aggregated_df are already defined\n",
    "# # ba_combined_df needs 'UTC Time at End of Hour', 'Balancing Authority', and 'Demand (MW)' columns\n",
    "# # serives_area_df should already have the 'Total_Population' calculated for each BA_Code and Year combination\n",
    "\n",
    "# # Step 1: Create a Year column in ba_combined_df\n",
    "# ba_combined_df['Year'] = pd.to_datetime(ba_combined_df['UTC Time at End of Hour']).dt.year\n",
    "\n",
    "# # Prepare the result list\n",
    "# expanded_results = []\n",
    "# # Initialize a set to store details of records where a match is not found or total_population is zero\n",
    "# unmatched_records = set()\n",
    "\n",
    "# # Step 2 & 3: Iterate through ba_combined_df and expand with matching records\n",
    "# for index, row in ba_combined_df.iterrows():\n",
    "#     year = row['Year']\n",
    "#     ba_code = row['Balancing Authority']\n",
    "\n",
    "#     try:\n",
    "#         # Attempt to directly convert or replace commas and then convert\n",
    "#         demand_mw = float(str(row['Demand (MW)']).replace(',', ''))\n",
    "#     except ValueError:\n",
    "#         print(f\"Cannot convert Demand (MW) to float for BA {ba_code} at {row['UTC Time at End of Hour']}. Using 0 as placeholder.\")\n",
    "#         demand_mw = 0  # Use a placeholder value or handle this scenario as appropriate\n",
    "    \n",
    "    \n",
    "#     # Find matching rows in serives_area_df\n",
    "#     matching_rows = serives_area_df[(serives_area_df['BA_Code'] == ba_code) & (serives_area_df['Year'] == year)]\n",
    "\n",
    "#     if matching_rows.empty:\n",
    "#         # If no matching rows are found, add the details to the unmatched_records set\n",
    "#         unmatched_records.add((year, ba_code, 'No FIPS - no matching row', demand_mw))\n",
    "#         continue  # Skip to the next row in ba_combined_df\n",
    "#     population = float(match_row['Population']) if pd.notna(match_row['Population']) else 0\n",
    "#     total_population = float(match_row['Total_Population']) if pd.notna(match_row['Total_Population']) else 0\n",
    "    \n",
    "#     for _, match_row in matching_rows.iterrows():\n",
    "#         population = match_row['Population']\n",
    "#         total_population = match_row['Total_Population']\n",
    "        \n",
    "#         if total_population > 0:  # Avoid division by zero\n",
    "#             adjusted_demand = (population / total_population) * demand_mw\n",
    "#             expanded_results.append({\n",
    "#                 'UTC Time at End of Hour': row['UTC Time at End of Hour'],\n",
    "#                 'County_FIPS': match_row['County_FIPS'],\n",
    "#                 'BA_Code': ba_code,\n",
    "#                 'Demand': adjusted_demand\n",
    "#             })\n",
    "#         else:\n",
    "#             # Handle the case of zero total population\n",
    "#             unmatched_records.add((year, ba_code, match_row['County_FIPS'], demand_mw))\n",
    "#             print(f'Error with {row[\"UTC Time at End of Hour\"]} for county {match_row[\"County_FIPS\"]} - zero total population.')\n",
    "\n",
    "# # Optionally, after processing\n",
    "# for unmatched in unmatched_records:\n",
    "#     print(f\"Unmatched record: Year {unmatched[0]}, BA_Code {unmatched[1]}, County_FIPS {unmatched[2]}, Demand_MW {unmatched[3]}\")\n",
    "\n",
    "# # Step 4: Convert expanded_results to DataFrame\n",
    "# expanded_results_df = pd.DataFrame(expanded_results)\n",
    "\n",
    "# # Optional: You might want to group by 'UTC Time at End of Hour', 'County_FIPS', 'BA_Code' and sum 'Demand' if necessary\n",
    "# # This step depends on whether you want to aggregate demands at this level\n",
    "# final_results_df = expanded_results_df.groupby(['UTC Time at End of Hour', 'County_FIPS', 'BA_Code'], as_index=False)['Demand'].sum()\n",
    "\n",
    "# # Save to CSV\n",
    "# final_results_df.to_csv(data_and_output_dir + 'output/final_expanded_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n",
      "1055321\n"
     ]
    }
   ],
   "source": [
    "print('go')\n",
    "# Define paths\n",
    "output_csv_path = data_and_output_dir+'output/final_expanded_results_demand.csv'  # Update this path\n",
    "checkpoint_path = data_and_output_dir+'/output/demand/checkpoint_for_demand.txt'  # Update this path\n",
    "\n",
    "# Function to get the last processed index from the checkpoint file\n",
    "def get_last_processed_index(checkpoint_path):\n",
    "    try:\n",
    "        with open(checkpoint_path, 'r') as f:\n",
    "            last_index = int(f.read())\n",
    "    except FileNotFoundError:\n",
    "        last_index = -1\n",
    "    return last_index\n",
    "\n",
    "# Function to update the checkpoint file with the last processed index\n",
    "def update_checkpoint(index, checkpoint_path):\n",
    "    with open(checkpoint_path, 'w') as f:\n",
    "        f.write(str(index))\n",
    "\n",
    "# Get the last processed index\n",
    "last_processed_index = get_last_processed_index(checkpoint_path)\n",
    "print(last_processed_index)\n",
    "\n",
    "# Check if the output CSV already exists; if not, write headers first\n",
    "# Check if the output CSV already exists; if not, write headers first\n",
    "if last_processed_index == -1:\n",
    "    if not os.path.exists(output_csv_path):  # Check if file exists\n",
    "        # Assuming the DataFrame structure, adjust column names as necessary\n",
    "        pd.DataFrame(columns=['UTC Time at End of Hour', 'County_FIPS', 'BA_Code', 'Demand']).to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Step 1: Create a Year column in ba_combined_df\n",
    "ba_combined_df['Year'] = pd.to_datetime(ba_combined_df['UTC Time at End of Hour']).dt.year\n",
    "ba_combined_df['Month'] = pd.to_datetime(ba_combined_df['UTC Time at End of Hour']).dt.month\n",
    "\n",
    "\n",
    "# Prepare the result list\n",
    "expanded_results = []\n",
    "# Initialize a set to store details of records where a match is not found or total_population is zero\n",
    "unmatched_records = set()\n",
    "\n",
    "# Process rows starting from the last checkpoint\n",
    "for index, row in ba_combined_df.iterrows():\n",
    "    if index <= last_processed_index:\n",
    "        continue  # Skip already processed rows\n",
    "    \n",
    "    year = row['Year']\n",
    "    month = row['Month']\n",
    "    ba_code = row['Balancing Authority']\n",
    "    # Construct the output CSV file path for the current month and year\n",
    "    monthly_output_csv_path = os.path.join(data_and_output_dir+'output/demand', f'final_expanded_results_demand_{year}_{month:02}.csv')\n",
    "\n",
    "    # Create a new CSV file with headers for each new month and year combination if it doesn't exist\n",
    "    if not os.path.exists(monthly_output_csv_path):\n",
    "        pd.DataFrame(columns=['UTC Time at End of Hour', 'County_FIPS', 'BA_Code', 'Demand','Population']).to_csv(monthly_output_csv_path, index=False)\n",
    "\n",
    "    try:\n",
    "        # Attempt to directly convert or replace commas and then convert\n",
    "        demand_mw = float(str(row['Demand (MW)']).replace(',', ''))\n",
    "    except ValueError:\n",
    "        print(f\"Cannot convert Demand (MW) to float for BA {ba_code} at {row['UTC Time at End of Hour']}. Using 0 as placeholder.\")\n",
    "        demand_mw = 0  # Use a placeholder value or handle this scenario as appropriate\n",
    "    \n",
    "    \n",
    "    # Find matching rows in serives_area_df\n",
    "    matching_rows = serives_area_df[(serives_area_df['BA_Code'] == ba_code) & (serives_area_df['Year'] == year)]\n",
    "\n",
    "    if matching_rows.empty:\n",
    "        # If no matching rows are found, add the details to the unmatched_records set\n",
    "        #unmatched_records.add((year, ba_code, 'No FIPS - no matching row'))\n",
    "        with open(monthly_output_csv_path, 'a', newline='') as f:\n",
    "                pd.DataFrame([{\n",
    "                    'UTC Time at End of Hour': row['UTC Time at End of Hour'],\n",
    "                    'County_FIPS': 00000,\n",
    "                    'BA_Code': ba_code,\n",
    "                    'Demand': demand_mw,\n",
    "                    'Population':0\n",
    "                }]).to_csv(f, header=False, index=False)\n",
    "        \n",
    "        continue  # Skip to the next row in ba_combined_df\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    for _, match_row in matching_rows.iterrows():\n",
    "        population = float(match_row['Population']) if pd.notna(match_row['Population']) else 0\n",
    "        total_population = float(match_row['Total_Population']) if pd.notna(match_row['Total_Population']) else 0\n",
    "        \n",
    "        if total_population > 0:  # Avoid division by zero\n",
    "            adjusted_demand = (population / total_population) * demand_mw\n",
    "            # expanded_results.append({\n",
    "            #     'UTC Time at End of Hour': row['UTC Time at End of Hour'],\n",
    "            #     'County_FIPS': match_row['County_FIPS'],\n",
    "            #     'BA_Code': ba_code,\n",
    "            #     'Demand': adjusted_demand\n",
    "            # })\n",
    "                # Append the result to the CSV file\n",
    "            with open(monthly_output_csv_path, 'a', newline='') as f:\n",
    "                pd.DataFrame([{\n",
    "                    'UTC Time at End of Hour': row['UTC Time at End of Hour'],\n",
    "                    'County_FIPS': match_row['County_FIPS'],\n",
    "                    'BA_Code': ba_code,\n",
    "                    'Demand': adjusted_demand,\n",
    "                    'Population':population\n",
    "                }]).to_csv(f, header=False, index=False)\n",
    "        else:\n",
    "            # Handle the case of zero total population\n",
    "            unmatched_records.add((year, ba_code, match_row['County_FIPS']))\n",
    "\n",
    "    # Update checkpoint after each successfully processed row\n",
    "    update_checkpoint(index, checkpoint_path)\n",
    "# Optionally, after processing\n",
    "for unmatched in unmatched_records:\n",
    "        print(f\"Unmatched record: Year {unmatched[0]}, BA_Code {unmatched[1]}, County_FIPS {unmatched[2]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the path to the result folder and the county_map CSV\n",
    "result_folder_path = data_and_output_dir+'output/demand' # Update this path\n",
    "county_map_csv_path = data_and_output_dir+'Input/county_map.csv'  # Update this path\n",
    "\n",
    "# Load the county_map DataFrame\n",
    "county_map_df = pd.read_csv(county_map_csv_path)\n",
    "\n",
    "# Initialize an empty DataFrame to store the results\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Read each CSV in the result folder one by one\n",
    "for file in os.listdir(result_folder_path):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(result_folder_path, file)\n",
    "        demand_data_df = pd.read_csv(file_path)\n",
    "\n",
    "        # Join with county_map on County_FIPS\n",
    "        combined_df = pd.merge(demand_data_df, county_map_df, left_on='County_FIPS', right_on='cnty_fips')\n",
    "\n",
    "        # Group by 'reeds_ba' and 'UTC Time at End of Hour', and sum 'Demand'\n",
    "        grouped_df = combined_df.groupby(['reeds_ba', 'UTC Time at End of Hour'], as_index=False)['Demand'].sum()\n",
    "\n",
    "        # Append to the result DataFrame\n",
    "        result_df = pd.concat([result_df, grouped_df])\n",
    "\n",
    "# Reset index after concatenating\n",
    "result_df = result_df.reset_index(drop=True)\n",
    "\n",
    "# Assuming you want to save the result to a CSV file\n",
    "result_df.to_csv(data_and_output_dir+'output/final_demand_aggregation.csv', index=False)  # Update this path\n",
    "\n",
    "# Return the result DataFrame\n",
    "result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>County_FIPS</th>\n",
       "      <th>BA_Code</th>\n",
       "      <th>Population</th>\n",
       "      <th>Total_Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6353</th>\n",
       "      <td>2019</td>\n",
       "      <td>01001</td>\n",
       "      <td>SOCO</td>\n",
       "      <td>55869.0</td>\n",
       "      <td>16834163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6354</th>\n",
       "      <td>2019</td>\n",
       "      <td>01003</td>\n",
       "      <td>SOCO</td>\n",
       "      <td>223234.0</td>\n",
       "      <td>16834163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6355</th>\n",
       "      <td>2019</td>\n",
       "      <td>01005</td>\n",
       "      <td>SOCO</td>\n",
       "      <td>24686.0</td>\n",
       "      <td>16834163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6356</th>\n",
       "      <td>2019</td>\n",
       "      <td>01007</td>\n",
       "      <td>SOCO</td>\n",
       "      <td>22394.0</td>\n",
       "      <td>16834163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6357</th>\n",
       "      <td>2019</td>\n",
       "      <td>01009</td>\n",
       "      <td>SOCO</td>\n",
       "      <td>57826.0</td>\n",
       "      <td>16834163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6599</th>\n",
       "      <td>2019</td>\n",
       "      <td>28111</td>\n",
       "      <td>SOCO</td>\n",
       "      <td>11973.0</td>\n",
       "      <td>16834163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6600</th>\n",
       "      <td>2019</td>\n",
       "      <td>28123</td>\n",
       "      <td>SOCO</td>\n",
       "      <td>28124.0</td>\n",
       "      <td>16834163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6601</th>\n",
       "      <td>2019</td>\n",
       "      <td>28129</td>\n",
       "      <td>SOCO</td>\n",
       "      <td>15916.0</td>\n",
       "      <td>16834163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6602</th>\n",
       "      <td>2019</td>\n",
       "      <td>28131</td>\n",
       "      <td>SOCO</td>\n",
       "      <td>18336.0</td>\n",
       "      <td>16834163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603</th>\n",
       "      <td>2019</td>\n",
       "      <td>28153</td>\n",
       "      <td>SOCO</td>\n",
       "      <td>20183.0</td>\n",
       "      <td>16834163.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year County_FIPS BA_Code  Population  Total_Population\n",
       "6353  2019       01001    SOCO     55869.0        16834163.0\n",
       "6354  2019       01003    SOCO    223234.0        16834163.0\n",
       "6355  2019       01005    SOCO     24686.0        16834163.0\n",
       "6356  2019       01007    SOCO     22394.0        16834163.0\n",
       "6357  2019       01009    SOCO     57826.0        16834163.0\n",
       "...    ...         ...     ...         ...               ...\n",
       "6599  2019       28111    SOCO     11973.0        16834163.0\n",
       "6600  2019       28123    SOCO     28124.0        16834163.0\n",
       "6601  2019       28129    SOCO     15916.0        16834163.0\n",
       "6602  2019       28131    SOCO     18336.0        16834163.0\n",
       "6603  2019       28153    SOCO     20183.0        16834163.0\n",
       "\n",
       "[251 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "748.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "result_file_path = output_csv_path\n",
    "results_df = pd.read_csv(result_file_path)\n",
    "\n",
    "# Filter for entries with the specified UTC Time and BA Code\n",
    "filtered_results = results_df[\n",
    "    (results_df['UTC Time at End of Hour'] == '01/01/2018 7:00:00 AM') &\n",
    "    (results_df['BA_Code'] == 'AEC')\n",
    "]\n",
    "\n",
    "# Sum the 'Demand' for the filtered entries\n",
    "demand_sum = filtered_results['Demand'].sum()\n",
    "demand_sum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
